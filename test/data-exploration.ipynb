{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports:\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV data into dataframe\n",
    "csv = pd.read_csv(\"../data/G2 software product overview.csv\")\n",
    "df = pd.DataFrame(csv)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevant_attributes(df):\n",
    "    # Select columns: 'seller', 'product_name', 'Features', 'categories', 'rating', and 'main_category'\n",
    "    df = df.loc[:, [ 'seller', 'product_name', 'Features', 'categories', 'rating', 'main_category']]\n",
    "    return df\n",
    "\n",
    "vendors_data = relevant_attributes(df.copy())\n",
    "vendors_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(vendors_data):\n",
    "    # Drop rows with missing data in column: 'Features'\n",
    "    vendors_data = vendors_data.dropna(subset=['Features'])\n",
    "    return vendors_data\n",
    "\n",
    "vendors_data_clean = clean_data(vendors_data.copy())\n",
    "vendors_data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert column values to list\n",
    "vendors_data_clean[\"Features\"] = vendors_data_clean[\"Features\"].apply(lambda x: json.loads(x))\n",
    "vendors_data_clean[\"categories\"] = vendors_data_clean[\"categories\"].apply(lambda x: json.loads(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Features \n",
    "extracted_features = []\n",
    "\n",
    "for category in vendors_data_clean[\"Features\"]:\n",
    "    feature_list = []\n",
    "    for features in category:\n",
    "        for feature in features['features']:\n",
    "            feature_list.append(feature['name'])\n",
    "        \n",
    "    extracted_features.append(feature_list)\n",
    "\n",
    "vendors_data_clean[\"feature_names\"] = extracted_features\n",
    "\n",
    "# Convert the list of categories into a concatenated string\n",
    "vendors_data_clean[\"categories_text\"] = vendors_data_clean[\"categories\"].apply(lambda x: \" \".join(x) if isinstance(x, list) else \"\")\n",
    "\n",
    "vendors_data_clean    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained sentence embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def get_embedding(text):\n",
    "    \"\"\"Generate embedding for a given text using the sentence transformer model.\"\"\"\n",
    "    return model.encode(text, convert_to_tensor=True)\n",
    "\n",
    "vendors_data_clean[\"main_category_embedding\"] = vendors_data_clean[\"main_category\"].apply(get_embedding)\n",
    "vendors_data_clean[\"categories_text_embedding\"] = vendors_data_clean[\"categories_text\"].apply(get_embedding)\n",
    "vendors_data_clean[\"feature_embeddings\"] = vendors_data_clean[\"feature_names\"].apply(\n",
    "    lambda features: [get_embedding(feature) for feature in features]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_feature_similarities(capability_embeddings, vendor_feature_embeddings):\n",
    "    \"\"\"Compute pairwise similarity scores between user capabilities and vendor features.\"\"\"\n",
    "    if not vendor_feature_embeddings:\n",
    "        return []  # Return an empty list if no features are available\n",
    "\n",
    "    vendor_feature_embeddings = torch.stack(vendor_feature_embeddings)  # Convert list to tensor\n",
    "    similarity_matrix = util.pytorch_cos_sim(torch.stack(capability_embeddings), vendor_feature_embeddings)\n",
    "\n",
    "    return similarity_matrix.tolist()  # Keeping as list of lists for now\n",
    "\n",
    "def compute_similarity(input_embedding, vendor_embeddings):\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between software_category and (main_category + categories_text)\n",
    "    \"\"\"\n",
    "    similarity_scores = util.pytorch_cos_sim(input_embedding, vendor_embeddings)\n",
    "    return similarity_scores.squeeze().tolist()\n",
    "\n",
    "# Example inputs\n",
    "software_category = \"Project Management Software\"\n",
    "capabilities = [\"Task Scheduling\", \"Time Tracking\"]\n",
    "\n",
    "# Generate embeddings\n",
    "software_category_embedding = get_embedding(software_category)  # Already a tensor\n",
    "capability_embeddings = [get_embedding(feature) for feature in capabilities]  # List of tensors\n",
    "\n",
    "# Compute category similarity\n",
    "vendors_data_clean[\"category_similarity\"] = vendors_data_clean.apply(\n",
    "    lambda row: max(compute_similarity(software_category_embedding, \n",
    "                                       torch.stack([row[\"main_category_embedding\"], row[\"categories_text_embedding\"]]))),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Compute feature similarity (list of scores for each vendor)\n",
    "vendors_data_clean[\"feature_similarities\"] = vendors_data_clean[\"feature_embeddings\"].apply(\n",
    "    lambda feature_emb: compute_feature_similarities(capability_embeddings, feature_emb)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filtered_vendors = vendors_data_clean[\n",
    "    vendors_data_clean[\"feature_similarities\"].apply(\n",
    "        lambda scores: any(score >= 0.6 for row in scores for score in row)  # Flatten the nested lists properly\n",
    "    )\n",
    "].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(427, 16)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_vendors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     seller  final_score  weighted_feature_similarity  \\\n",
      "916                     QAD     0.525779                     0.331113   \n",
      "174                 CAST AI     0.472296                     0.263279   \n",
      "988                 Fullbay     0.468945                     0.249921   \n",
      "363                  Intuit     0.465330                     0.279043   \n",
      "894           Take 44, Inc.     0.460226                     0.246037   \n",
      "765  Willo Technologies Ltd     0.458308                     0.243297   \n",
      "683                AlignOps     0.458302                     0.243288   \n",
      "334              Pocketstop     0.457726                     0.242465   \n",
      "535                  Deputy     0.456907                     0.258438   \n",
      "873      Contractor Foreman     0.456373                     0.266247   \n",
      "\n",
      "     category_similarity  rating  \n",
      "916             0.288011     4.9  \n",
      "174             0.413441     4.8  \n",
      "988             0.382038     4.9  \n",
      "363             0.393246     4.5  \n",
      "894             0.382306     4.8  \n",
      "765             0.464520     4.8  \n",
      "683             0.393246     4.8  \n",
      "334             0.324263     4.8  \n",
      "535             0.568492     4.6  \n",
      "873             0.578517     4.5  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Ensure vendors have at least one feature similarity score >= 0.6\n",
    "filtered_vendors = vendors_data_clean[\n",
    "    vendors_data_clean[\"feature_similarities\"].apply(\n",
    "        lambda scores: any(score >= 0.6 for row in scores for score in row)  # Flatten the nested lists properly\n",
    "    )\n",
    "].copy()  # Copy to avoid modifying the original DataFrame\n",
    "\n",
    "\n",
    "#  Step 1: Create a new copy for ranking to avoid modifying the original filtered vendors\n",
    "ranked_vendors = filtered_vendors.copy()\n",
    "\n",
    "#  Step 2: Compute weighted feature similarity per vendor\n",
    "ranked_vendors.loc[:, \"weighted_feature_similarity\"] = ranked_vendors[\"feature_similarities\"].apply(\n",
    "    lambda scores: sum(score for row in scores for score in row) / sum(len(row) for row in scores) if scores else 0\n",
    ")\n",
    "\n",
    "#  Step 3: Normalize vendor ratings between 0 and 1\n",
    "if not ranked_vendors.empty:\n",
    "    min_rating = ranked_vendors[\"rating\"].min()\n",
    "    max_rating = ranked_vendors[\"rating\"].max()\n",
    "    if max_rating > min_rating:  # Avoid division by zero\n",
    "        ranked_vendors.loc[:, \"normalized_rating\"] = ranked_vendors[\"rating\"].apply(\n",
    "            lambda r: (r - min_rating) / (max_rating - min_rating)\n",
    "        )\n",
    "    else:\n",
    "        ranked_vendors.loc[:, \"normalized_rating\"] = 0\n",
    "else:\n",
    "    ranked_vendors[\"normalized_rating\"] = []\n",
    "\n",
    "#  Step 4: Compute final ranking score (70% feature similarity, 30% rating)\n",
    "ranked_vendors.loc[:, \"final_score\"] = (\n",
    "    0.7 * ranked_vendors[\"weighted_feature_similarity\"] + \n",
    "    0.3 * ranked_vendors[\"normalized_rating\"]\n",
    ")\n",
    "\n",
    "#  Step 5: Sort vendors by final ranking score (descending order)\n",
    "ranked_vendors = ranked_vendors.sort_values(by=\"final_score\", ascending=False)\n",
    "\n",
    "#  Step 6: Select relevant columns for output\n",
    "top_vendors = ranked_vendors[[\"seller\", \"final_score\", \"weighted_feature_similarity\", \"category_similarity\", \"rating\"]]\n",
    "\n",
    "#  Step 7: Display top vendors (only if they exist)\n",
    "if not top_vendors.empty:\n",
    "    print(top_vendors.head(min(10, len(top_vendors))))  # Show up to 10 vendors, or fewer if less exist\n",
    "else:\n",
    "    print(\"No vendors met the similarity threshold.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Templates',\n",
       " 'Workflows',\n",
       " 'Procedures',\n",
       " 'Planning',\n",
       " 'Scheduling',\n",
       " 'Collaboration',\n",
       " 'Monitoring',\n",
       " 'KPIs',\n",
       " 'Optimization']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vendors_data_clean['feature_names'][916]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
